<!DOCTYPE html>
<html>
<head>
    



    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Boris Ivanovic</title>

    <meta name="description" content="Deep learning and robotics">
    <!-- Bootstrap Core CSS -->
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <!-- <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous"> -->
    <!-- <link rel="stylesheet" href="/css/bootstrap.min.css"> -->
    <link href="https://fonts.googleapis.com/css?family=Montserrat:300,600" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=Raleway:400,700" rel="stylesheet">

	<!-- JabRef CSS -->
	<link rel="stylesheet" href="https://stanfordasl.github.io/css/JabRef.css">
	 
    <link rel="canonical" href="http://asl.stanford.edu/people/boris-ivanovic/"> 
    <!-- Not required -->
    <!-- <link rel="alternate" type="application/rss+xml" title="Autonomous Systems Laboratory" href="https://stanfordasl.github.io /feed.xml "> -->
    <!-- Custom Fonts -->
	<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <!-- <link href="css/font-awesome.min.css" rel="stylesheet" type="text/css"> -->
    
    <!-- My CSS -->
    <link rel="stylesheet" href="https://stanfordasl.github.io/css/my.css"> 

    <!-- Analytics -->
    
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-124680200-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-124680200-1');
    </script>
    

    <!-- Favicons -->
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#2864b7">
    <meta name="msapplication-TileColor" content="#2864b7">
    <meta name="theme-color" content="#ffffff">

</head>





  <body id="page-top" class="index">
    <!-- Navigation -->
<nav id="mainNav" class="navbar navbar-default navbar-custom"> <!-- navbar-fixed-top -->
    <div class="container navbar-items">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="row">
            <div class="col-md-3" style="z-index: 1;">
                <div class="navbar-header page-scroll">
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="/">
                        <img src="https://stanfordasl.github.io/img/ASL_Logo_White.png" alt="">
                    </a>
                </div>
            </div>
            <div class="col-md-9">
                <div class="row">
                    <!-- Collect the nav links, forms, and other content for toggling -->
                    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                        <ul class="nav navbar-nav navbar-right">
                            <li class="hidden">
                                <a href="#page-top"></a>
                            </li>
                            <!-- 
                            <li class="page-scroll">
                                <a href="/">Home</a>
                            </li>
                             -->
                            
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                                    
                                    <li class="page-scroll">
                                        <a href="/projects/">Projects</a>
                                    </li>
                                    
                                
                            
                                
                            
                                
                            
                                
                            
                                
                                    
                                    <li class="page-scroll">
                                        <a href="/publications/">Publications</a>
                                    </li>
                                    
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                            
                                
                                    
                                    <li class="page-scroll">
                                        <a href="/people/">People</a>
                                    </li>
                                    
                                
                            
                                
                            
                                
                                    
                                    <li class="page-scroll">
                                        <a href="/faq/">FAQ</a>
                                    </li>
                                    
                                
                            
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container-fluid -->
</nav>

    <header>
      <div class="container">
        <div class="row" style="margin-top: 40px;">
  	      <div class="col-md-5" style="margin-bottom: 20px;">
  	          <img src="../../img/people/BorisIvanovic.jpg" alt="Boris Ivanovic" class="img-responsive">
            <h3>Contacts:</h3>
            <a href="//www.borisivanovic.com" target="_blank">Personal Webpage</a>
  		    </div>
    		  <div class="col-md-7">
            <h2 style="margin-top: 0px;">Boris Ivanovic</h2>
    		    <hr>
            <p>Boris Ivanovic is a Ph.D. student in the Aeronautics and Astronautics Department. He obtained a Master’s in Computer Science from Stanford in 2018, specializing in Artificial Intelligence (AI). Prior to joining Stanford, he obtained a Bachelor’s of Applied Science with high honors in 2016 from the University of Toronto’s rigorous Engineering Science program, majoring in Electrical and Computer Engineering with a Robotics/Mechatronics minor.</p>

<p>His previous research work spans computer vision, machine learning, data science, and robotics. He has also conducted numerous internships, from Amazon’s Prime Air drone delivery team to a summer at ETH Zurich in Professor Raffaello d’Andrea’s Flying Machine Arena.</p>

<p>Boris’ research interests are to combine deep learning with principled methods from robotics, optimization, and control theory to create safe and reliable learning algorithms that can be deployed in the real world.</p>

<p>In his spare time, Boris enjoys playing tennis, skiing, hiking, traveling, watching movies, and thinking about cooking.</p>

            <br>
            
    		  </div>
  		</div>
      <div class="row">
        <div class="col-md-12">
        
          <h2 style="margin-top: 0px;">ASL Publications</h2>
          
          
          <ol class="bibliography"><li>
 


<span class="entry" id="SchaeferLeungEtAl2021">S. Schaefer, K. Leung, B. Ivanovic, and M. Pavone, <a class="entry-title" href="https://arxiv.org/abs/2012.01027">“Leveraging Neural Network Gradients within Trajectory Optimization for Proactive Human-Robot Interactions,”</a> in <i>Proc. IEEE Conf. on Robotics and Automation</i>, Xi’an, China, 2021. (Submitted)</span> 
<p class="infolinks">[<a href="javascript:toggleInfo('SchaeferLeungEtAl2021','bibtex')">BibTeX</a>] [<a href="javascript:toggleInfo('SchaeferLeungEtAl2021','abstract')">Abstract</a>]</p>
<span id="abs_SchaeferLeungEtAl2021" class="abstract noshow">
	<p class="abstract"><b>Abstract:</b> To achieve seamless human-robot interactions, robots need to intimately reason about complex interaction dynamics and future human behaviors within their motion planning process. However, there is a disconnect between state-of-the-art neural network-based human behavior models and robot motion planners—either the behavior models are limited in their consideration of downstream planning or a simplified behavior model is used to ensure tractability of the planning problem. In this work, we present a framework that fuses together the interpretability and flexibility of trajectory optimization (TO) with the predictive power of state-of-the-art human trajectory prediction models. In particular, we leverage gradient information from data-driven prediction models to explicitly reason about human-robot interaction dynamics within a gradient-based TO problem. We demonstrate the efficacy of our approach in a multi-agent scenario whereby a robot is required to safely and efficiently navigate through a crowd of up to ten pedestrians. We compare against a variety of planning methods, and show that by explicitly accounting for interaction dynamics within the planner, our method offers safer and more efficient behaviors, even yielding proactive and nuanced behaviors such as waiting for a pedestrian to pass before moving.</p>
</span>
<span id="bib_SchaeferLeungEtAl2021" class="bibtex noshow">
	<pre>@inproceedings{SchaeferLeungEtAl2021,
  author = {Schaefer, S. and Leung, K. and Ivanovic, B. and Pavone, M.},
  title = {Leveraging Neural Network Gradients within Trajectory Optimization for Proactive Human-Robot Interactions},
  booktitle = {{Proc. IEEE Conf. on Robotics and Automation}},
  year = {2021},
  note = {Submitted},
  address = {Xi'an, China},
  month = may,
  url = {https://arxiv.org/abs/2012.01027},
  keywords = {sub},
  owner = {borisi},
  timestamp = {2020-11-01}
}
</pre>
</span>
<!-- <span id="key_SchaeferLeungEtAl2021" >
	<b>Keywords</b>:
	sub
</span> --></li>
<li>
 


<span class="entry" id="IvanovicLeungEtAl2020">B. Ivanovic, K. Leung, E. Schmerling, and M. Pavone, <a class="entry-title" href="https://arxiv.org/abs/2008.03880">“Multimodal Deep Generative Models for Trajectory Prediction: A Conditional Variational Autoencoder Approach,”</a> <i>IEEE Robotics and Automation Letters</i>, vol. 6, no. 2, pp. 295–302, Apr. 2021. (In Press)</span> 
<p class="infolinks">[<a href="javascript:toggleInfo('IvanovicLeungEtAl2020','bibtex')">BibTeX</a>] [<a href="javascript:toggleInfo('IvanovicLeungEtAl2020','abstract')">Abstract</a>]</p>
<span id="abs_IvanovicLeungEtAl2020" class="abstract noshow">
	<p class="abstract"><b>Abstract:</b> Human behavior prediction models enable robots to anticipate how humans may react to their actions, and hence are instrumental to devising safe and proactive robot planning algorithms. However, modeling complex interaction dynamics and capturing the possibility of many possible outcomes in such interactive settings is very challenging, which has recently prompted the study of several different approaches. In this work, we provide a self-contained tutorial on a conditional variational autoencoder (CVAE) approach to human behavior prediction which, at its core, can produce a multimodal probability distribution over future human trajectories conditioned on past interactions and candidate robot future actions. Specifically, the goals of this tutorial paper are to review and build a taxonomy of state-of-the-art methods in human behavior prediction, from physics-based to purely data-driven methods, provide a rigorous yet easily accessible description of a data-driven, CVAE-based approach, highlight important design characteristics that make this an attractive model to use in the context of model-based planning for human-robot interactions, and provide important design considerations when using this class of models.</p>
</span>
<span id="bib_IvanovicLeungEtAl2020" class="bibtex noshow">
	<pre>@article{IvanovicLeungEtAl2020,
  author = {Ivanovic, B. and Leung, K. and Schmerling, E. and Pavone, M.},
  title = {Multimodal Deep Generative Models for Trajectory Prediction: A Conditional Variational Autoencoder Approach},
  journal = {{IEEE Robotics and Automation Letters}},
  volume = {6},
  number = {2},
  pages = {295--302},
  year = {2021},
  note = {In Press},
  month = apr,
  url = {https://arxiv.org/abs/2008.03880},
  keywords = {press},
  owner = {borisi},
  timestamp = {2020-12-23}
}
</pre>
</span>
<!-- <span id="key_IvanovicLeungEtAl2020" >
	<b>Keywords</b>:
	press
</span> --></li>
<li>
 


<span class="entry" id="ItkinaIvanovicEtAl2019">M. Itkina, B. Ivanovic, R. Senanayake, M. J. Kochenderfer, and M. Pavone, <a class="entry-title" href="https://arxiv.org/abs/2010.09164">“Evidential Sparsification of Multimodal Latent Spaces in Conditional Variational Autoencoders,”</a> in <i>Conf. on Neural Information Processing Systems</i>, 2020.</span> 
<p class="infolinks">[<a href="javascript:toggleInfo('ItkinaIvanovicEtAl2019','bibtex')">BibTeX</a>] [<a href="javascript:toggleInfo('ItkinaIvanovicEtAl2019','abstract')">Abstract</a>]</p>
<span id="abs_ItkinaIvanovicEtAl2019" class="abstract noshow">
	<p class="abstract"><b>Abstract:</b> Discrete latent spaces in variational autoencoders have been shown to effectively capture the data distribution for many real-world problems such as natural language understanding, human intent prediction, and visual scene representation. However, discrete latent spaces need to be sufficiently large to capture the complexities of real-world data, rendering downstream tasks computationally challenging. For instance, performing motion planning in a high-dimensional latent representation of the environment could be intractable. We consider the problem of sparsifying the discrete latent space of a trained conditional variational autoencoder, while preserving its learned multimodality. As a post hoc latent space reduction technique, we use evidential theory to identify the latent classes that receive direct evidence from a particular input condition and filter out those that do not. Experiments on diverse tasks, such as image generation and human behavior prediction, demonstrate the effectiveness of our proposed technique at reducing the discrete latent sample space size of a model while maintaining its learned multimodality.</p>
</span>
<span id="bib_ItkinaIvanovicEtAl2019" class="bibtex noshow">
	<pre>@inproceedings{ItkinaIvanovicEtAl2019,
  author = {Itkina, M. and Ivanovic, B. and Senanayake, R. and Kochenderfer, M. J. and Pavone, M.},
  title = {Evidential Sparsification of Multimodal Latent Spaces in Conditional Variational Autoencoders},
  booktitle = {{Conf. on Neural Information Processing Systems}},
  year = {2020},
  address = {},
  month = dec,
  owner = {borisi},
  timestamp = {2020-09-27},
  url = {https://arxiv.org/abs/2010.09164}
}
</pre>
</span>
<!-- <span id="key_ItkinaIvanovicEtAl2019" >
	<b>Keywords</b>:
	
</span> --></li>
<li>
 


<span class="entry" id="IvanovicElhafsiEtAl2020">B. Ivanovic, A. Elhafsi, G. Rosman, A. Gaidon, and M. Pavone, <a class="entry-title" href="https://arxiv.org/abs/2009.07517">“MATS: An Interpretable Trajectory Forecasting Representation for Planning and Control,”</a> in <i>Conf. on Robot Learning</i>, 2020.</span> 
<p class="infolinks">[<a href="javascript:toggleInfo('IvanovicElhafsiEtAl2020','bibtex')">BibTeX</a>] [<a href="javascript:toggleInfo('IvanovicElhafsiEtAl2020','abstract')">Abstract</a>]</p>
<span id="abs_IvanovicElhafsiEtAl2020" class="abstract noshow">
	<p class="abstract"><b>Abstract:</b> Reasoning about human motion is a core component of modern human-robot interactive systems. In particular, one of the main uses of behavior prediction in autonomous systems is to inform ego-robot motion planning and control. However, a majority of planning and control algorithms reason about system dynamics rather than the predicted agent tracklets that are commonly output by trajectory forecasting methods, which can hinder their integration. Towards this end, we propose Mixtures of Affine Time-varying Systems (MATS) as an output representation for trajectory forecasting that is more amenable to downstream planning and control use. Our approach leverages successful ideas from probabilistic trajectory forecasting works to learn dynamical system representations that are well-studied in the planning and control literature. We integrate our predictions with a proposed multimodal planning methodology and demonstrate significant computational efficiency improvements on a large-scale autonomous driving dataset.</p>
</span>
<span id="bib_IvanovicElhafsiEtAl2020" class="bibtex noshow">
	<pre>@inproceedings{IvanovicElhafsiEtAl2020,
  author = {Ivanovic, B. and Elhafsi, A. and Rosman, G. and Gaidon, A. and Pavone, M.},
  title = {{MATS}: An Interpretable Trajectory Forecasting Representation for Planning and Control},
  booktitle = {{Conf. on Robot Learning}},
  year = {2020},
  month = nov,
  owner = {borisi},
  timestamp = {2020-10-14},
  url = {https://arxiv.org/abs/2009.07517}
}
</pre>
</span>
<!-- <span id="key_IvanovicElhafsiEtAl2020" >
	<b>Keywords</b>:
	
</span> --></li>
<li>
 


<span class="entry" id="NishimuraIvanovicEtAl2020">H. Nishimura, B. Ivanovic, A. Gaidon, M. Pavone, and M. Schwager, <a class="entry-title" href="https://arxiv.org/abs/2009.05702">“Risk-Sensitive Sequential Action Control with Multi-Modal Human Trajectory Forecasting for Safe Crowd-Robot Interaction,”</a> in <i>IEEE/RSJ Int. Conf. on Intelligent Robots &amp; Systems</i>, 2020.</span> 
<p class="infolinks">[<a href="javascript:toggleInfo('NishimuraIvanovicEtAl2020','bibtex')">BibTeX</a>] [<a href="javascript:toggleInfo('NishimuraIvanovicEtAl2020','abstract')">Abstract</a>]</p>
<span id="abs_NishimuraIvanovicEtAl2020" class="abstract noshow">
	<p class="abstract"><b>Abstract:</b> This paper presents a novel online framework for safe crowd-robot interaction based on risk-sensitive stochastic optimal control, wherein the risk is modeled by the entropic risk measure. The control algorithm relies on mode insertion gradient optimization for this risk measure as well as Monte Carlo sampling from Trajectron++, a state-of-the-art generative model that produces multimodal probabilistic trajectory forecasts for multiple interacting agents. Our modular approach decouples the crowd-robot interaction into learning-based prediction and model-based control, which is advantageous compared to end-to-end policy learning methods in that it allows the robot’s desired behavior to be specified at run time. In particular, we show that the robot exhibits diverse interaction behavior by varying the risk sensitivity parameter. A simulation study and a real-world experiment show that the proposed online framework can accomplish safe and efficient navigation while avoiding collisions with more than 50 humans in the scene.</p>
</span>
<span id="bib_NishimuraIvanovicEtAl2020" class="bibtex noshow">
	<pre>@inproceedings{NishimuraIvanovicEtAl2020,
  author = {Nishimura, H. and Ivanovic, B. and Gaidon, A. and Pavone, M. and Schwager, M.},
  title = {Risk-Sensitive Sequential Action Control with Multi-Modal Human Trajectory Forecasting for Safe Crowd-Robot Interaction},
  booktitle = {{IEEE/RSJ Int. Conf. on Intelligent Robots \& Systems}},
  year = {2020},
  address = {},
  month = oct,
  owner = {borisi},
  timestamp = {2020-07-03},
  url = {https://arxiv.org/abs/2009.05702}
}
</pre>
</span>
<!-- <span id="key_NishimuraIvanovicEtAl2020" >
	<b>Keywords</b>:
	
</span> --></li>
<li>
 


<span class="entry" id="SalzmannIvanovicEtAl2020">T. Salzmann, B. Ivanovic, P. Chakravarty, and M. Pavone, <a class="entry-title" href="https://arxiv.org/abs/2001.03093">“Trajectron++: Dynamically-Feasible Trajectory Forecasting With Heterogeneous Data,”</a> in <i>European Conf. on Computer Vision</i>, 2020.</span> 
<p class="infolinks">[<a href="javascript:toggleInfo('SalzmannIvanovicEtAl2020','bibtex')">BibTeX</a>] [<a href="javascript:toggleInfo('SalzmannIvanovicEtAl2020','abstract')">Abstract</a>]</p>
<span id="abs_SalzmannIvanovicEtAl2020" class="abstract noshow">
	<p class="abstract"><b>Abstract:</b> Reasoning about human motion is an important prerequisite to safe and socially-aware robotic navigation. As a result, multi-agent behavior prediction has become a core component of modern human-robot interactive systems, such as self-driving cars. While there exist many methods for trajectory forecasting, most do not enforce dynamic constraints and do not account for environmental information (e.g., maps). Towards this end, we present Trajectron++, a modular, graph-structured recurrent model that forecasts the trajectories of a general number of diverse agents while incorporating agent dynamics and heterogeneous data (e.g., semantic maps). Trajectron++ is designed to be tightly integrated with robotic planning and control frameworks; for example, it can produce predictions that are optionally conditioned on ego-agent motion plans. We demonstrate its performance on several challenging real-world trajectory forecasting datasets, outperforming a wide array of state-of-the-art deterministic and generative methods.</p>
</span>
<span id="bib_SalzmannIvanovicEtAl2020" class="bibtex noshow">
	<pre>@inproceedings{SalzmannIvanovicEtAl2020,
  author = {Salzmann, T. and Ivanovic, B. and Chakravarty, P. and Pavone, M.},
  title = {Trajectron++: Dynamically-Feasible Trajectory Forecasting With Heterogeneous Data},
  booktitle = {{European Conf. on Computer Vision}},
  year = {2020},
  address = {},
  month = aug,
  owner = {borisi},
  timestamp = {2020-09-14},
  url = {https://arxiv.org/abs/2001.03093}
}
</pre>
</span>
<!-- <span id="key_SalzmannIvanovicEtAl2020" >
	<b>Keywords</b>:
	
</span> --></li>
<li>
 


<span class="entry" id="ElhafsiIvanovicEtAl2020">A. Elhafsi, B. Ivanovic, L. Janson, and M. Pavone, <a class="entry-title" href="https://arxiv.org/abs/1910.08184">“Map-Predictive Motion Planning in Unknown Environments,”</a> in <i>Proc. IEEE Conf. on Robotics and Automation</i>, Paris, France, 2020.</span> 
<p class="infolinks">[<a href="javascript:toggleInfo('ElhafsiIvanovicEtAl2020','bibtex')">BibTeX</a>] [<a href="javascript:toggleInfo('ElhafsiIvanovicEtAl2020','abstract')">Abstract</a>]</p>
<span id="abs_ElhafsiIvanovicEtAl2020" class="abstract noshow">
	<p class="abstract"><b>Abstract:</b> Algorithms for motion planning in unknown environments are generally limited in their ability to reason about the structure of the unobserved environment. As such, current methods generally navigate unknown environments by relying on heuristic methods to choose intermediate objectives along frontiers. We present a unified method that combines map prediction and motion planning for safe, time-efficient autonomous navigation of unknown environments by dynamically-constrained robots. We propose a data-driven method for predicting the map of the unobserved environment, using the robot’s observations of its surroundings as context. These map predictions are then used to plan trajectories from the robot’s position to the goal without requiring frontier selection. We demonstrate that our map-predictive motion planning strategy yields a substantial improvement in trajectory time over a naive frontier pursuit method and demonstrates similar performance to methods using more sophisticated frontier selection heuristics with significantly shorter computation time.</p>
</span>
<span id="bib_ElhafsiIvanovicEtAl2020" class="bibtex noshow">
	<pre>@inproceedings{ElhafsiIvanovicEtAl2020,
  author = {Elhafsi, A. and Ivanovic, B. and Janson, L. and Pavone, M.},
  title = {Map-Predictive Motion Planning in Unknown Environments},
  booktitle = {{Proc. IEEE Conf. on Robotics and Automation}},
  year = {2020},
  address = {Paris, France},
  month = jun,
  url = {https://arxiv.org/abs/1910.08184},
  owner = {borisi},
  timestamp = {2019-10-21}
}
</pre>
</span>
<!-- <span id="key_ElhafsiIvanovicEtAl2020" >
	<b>Keywords</b>:
	
</span> --></li>
<li>
 


<span class="entry" id="IvanovicPavone2019">B. Ivanovic and M. Pavone, <a class="entry-title" href="https://arxiv.org/abs/1810.05993">“The Trajectron: Probabilistic Multi-Agent Trajectory Modeling with Dynamic Spatiotemporal Graphs,”</a> in <i>IEEE Int. Conf. on Computer Vision</i>, Seoul, South Korea, 2019.</span> 
<p class="infolinks">[<a href="javascript:toggleInfo('IvanovicPavone2019','bibtex')">BibTeX</a>] [<a href="javascript:toggleInfo('IvanovicPavone2019','abstract')">Abstract</a>]</p>
<span id="abs_IvanovicPavone2019" class="abstract noshow">
	<p class="abstract"><b>Abstract:</b> Developing safe human-robot interaction systems is a necessary step towards the widespread integration of autonomous agents in society. A key component of such systems is the ability to reason about the many potential futures (e.g. trajectories) of other agents in the scene. Towards this end, we present the Trajectron, a graph-structured model that predicts many potential future trajectories of multiple agents simultaneously in both highly dynamic and multimodal scenarios (i.e. where the number of agents in the scene is time-varying and there are many possible highly-distinct futures for each agent). It combines tools from recurrent sequence modeling and variational deep generative modeling to produce a distribution of future trajectories for each agent in a scene. We demonstrate the performance of our model on several datasets, obtaining state-of-the-art results on standard trajectory prediction metrics as well as introducing a new metric for comparing models that output distributions.</p>
</span>
<span id="bib_IvanovicPavone2019" class="bibtex noshow">
	<pre>@inproceedings{IvanovicPavone2019,
  author = {Ivanovic, B. and Pavone, M.},
  title = {The {Trajectron}: Probabilistic Multi-Agent Trajectory Modeling with Dynamic Spatiotemporal Graphs},
  booktitle = {{IEEE Int. Conf. on Computer Vision}},
  year = {2019},
  address = {Seoul, South Korea},
  month = oct,
  url = {https://arxiv.org/abs/1810.05993},
  owner = {borisi},
  timestamp = {2019-07-22}
}
</pre>
</span>
<!-- <span id="key_IvanovicPavone2019" >
	<b>Keywords</b>:
	
</span> --></li>
<li>
 


<span class="entry" id="IvanovicHarrisonEtAl2019">B. Ivanovic, J. Harrison, A. Sharma, M. Chen, and M. Pavone, <a class="entry-title" href="https://arxiv.org/pdf/1806.06161.pdf">“BaRC: Backward Reachability Curriculum for Robotic Reinforcement Learning,”</a> in <i>Proc. IEEE Conf. on Robotics and Automation</i>, Montreal, Canada, 2019.</span> 
<p class="infolinks">[<a href="javascript:toggleInfo('IvanovicHarrisonEtAl2019','bibtex')">BibTeX</a>] [<a href="javascript:toggleInfo('IvanovicHarrisonEtAl2019','abstract')">Abstract</a>]</p>
<span id="abs_IvanovicHarrisonEtAl2019" class="abstract noshow">
	<p class="abstract"><b>Abstract:</b> Model-free Reinforcement Learning (RL) offers an attractive approach to learn control policies for high-dimensional systems, but its relatively poor sample complexity often forces training in simulated environments. Even in simulation, goal-directed tasks whose natural reward function is sparse remain intractable for state-of-the-art model-free algorithms for continuous control. The bottleneck in these tasks is the prohibitive amount of exploration required to obtain a learning signal from the initial state of the system. In this work, we leverage physical priors in the form of an approximate system dynamics model to design a curriculum scheme for a model-free policy optimization algorithm. Our Backward Reachability Curriculum (BaRC) begins policy training from states that require a small number of actions to accomplish the task, and expands the initial state distribution backwards in a dynamically-consistent manner once the policy optimization algorithm demonstrates sufficient performance. BaRC is general, in that it can accelerate training of any model-free RL algorithm on a broad class of goal-directed continuous control MDPs. Its curriculum strategy is physically intuitive, easy-to-tune, and allows incorporating physical priors to accelerate training without hindering the performance, flexibility, and applicability of the model-free RL algorithm. We evaluate our approach on two representative dynamic robotic learning problems and find substantial performance improvement relative to previous curriculum generation techniques and naïve exploration strategies</p>
</span>
<span id="bib_IvanovicHarrisonEtAl2019" class="bibtex noshow">
	<pre>@inproceedings{IvanovicHarrisonEtAl2019,
  author = {Ivanovic, B. and Harrison, J. and Sharma, A. and Chen, M. and Pavone, M.},
  title = {{BaRC:} Backward Reachability Curriculum for Robotic Reinforcement Learning},
  booktitle = {{Proc. IEEE Conf. on Robotics and Automation}},
  year = {2019},
  address = {Montreal, Canada},
  month = may,
  url = {https://arxiv.org/pdf/1806.06161.pdf},
  owner = {borisi},
  timestamp = {2018-09-05}
}
</pre>
</span>
<!-- <span id="key_IvanovicHarrisonEtAl2019" >
	<b>Keywords</b>:
	
</span> --></li>
<li>
 


<span class="entry" id="IvanovicSchmerlingEtAl2018">B. Ivanovic, E. Schmerling, K. Leung, and M. Pavone, <a class="entry-title" href="https://arxiv.org/pdf/1803.02015.pdf">“Generative Modeling of Multimodal Multi-Human Behavior,”</a> in <i>IEEE/RSJ Int. Conf. on Intelligent Robots &amp; Systems</i>, Madrid, Spain, 2018.</span> 
<p class="infolinks">[<a href="javascript:toggleInfo('IvanovicSchmerlingEtAl2018','bibtex')">BibTeX</a>] [<a href="javascript:toggleInfo('IvanovicSchmerlingEtAl2018','abstract')">Abstract</a>]</p>
<span id="abs_IvanovicSchmerlingEtAl2018" class="abstract noshow">
	<p class="abstract"><b>Abstract:</b> This work presents a methodology for modeling and predicting human behavior in settings with N humans interacting in highly multimodal scenarios (i.e. where there are many possible highly-distinct futures). A motivating example includes robots interacting with humans in crowded environments, such as self-driving cars operating alongside human-driven vehicles or human-robot collaborative bin packing in a warehouse. Our approach to model human behavior in such uncertain environments is to model humans in the scene as nodes in a graphical model, with edges encoding relationships between them. For each human, we learn a multimodal probability distribution over future actions from a dataset of multi-human interactions. Learning such distributions is made possible by recent advances in the theory of conditional variational autoencoders and deep learning approximations of probabilistic graphical models. Specifically, we learn action distributions conditioned on interaction history, neighboring human behavior, and candidate future agent behavior in order to take into account response dynamics. We demonstrate the performance of such a modeling approach in modeling basketball player trajectories, a highly multimodal, multi-human scenario which serves as a proxy for many robotic applications.</p>
</span>
<span id="bib_IvanovicSchmerlingEtAl2018" class="bibtex noshow">
	<pre>@inproceedings{IvanovicSchmerlingEtAl2018,
  author = {Ivanovic, B. and Schmerling, E. and Leung, K. and Pavone, M.},
  title = {Generative Modeling of Multimodal Multi-Human Behavior},
  booktitle = {{IEEE/RSJ Int. Conf. on Intelligent Robots \& Systems}},
  year = {2018},
  address = {Madrid, Spain},
  month = oct,
  url = {https://arxiv.org/pdf/1803.02015.pdf},
  owner = {borisi},
  timestamp = {2018-10-14}
}
</pre>
</span>
<!-- <span id="key_IvanovicSchmerlingEtAl2018" >
	<b>Keywords</b>:
	
</span> --></li>
<li>
 


<span class="entry" id="HarrisonGargEtAl2017">J. Harrison, A. Garg, B. Ivanovic, Y. Zhu, S. Savarese, F.-F. Li, and M. Pavone, <a class="entry-title" href="https://arxiv.org/pdf/1707.04674.pdf">“ADAPT: Zero-Shot Adaptive Policy Transfer for Stochastic Dynamical Systems,”</a> in <i>Int. Symp. on Robotics Research</i>, Puerto Varas, Chile, 2017.</span> 
<p class="infolinks">[<a href="javascript:toggleInfo('HarrisonGargEtAl2017','bibtex')">BibTeX</a>] [<a href="javascript:toggleInfo('HarrisonGargEtAl2017','abstract')">Abstract</a>]</p>
<span id="abs_HarrisonGargEtAl2017" class="abstract noshow">
	<p class="abstract"><b>Abstract:</b> Model-free policy learning has enabled robust performance of complex tasks with relatively simple algorithms. However, this simplicity comes at the cost of requiring an Oracle and arguably very poor sample complexity. This renders such methods unsuitable for physical systems. Variants of model-based methods address this problem through the use of simulators, however, this gives rise to the problem of policy transfer from simulated to the physical system. Model mismatch due to systematic parameter shift and unmodelled dynamics error may cause suboptimal or unsafe behavior upon direct transfer. We introduce the Adaptive Policy Transfer for Stochastic Dynamics (ADAPT) algorithm that achieves provably safe and robust, dynamically-feasible zero-shot transfer of RL-policies to new domains with dynamics error. ADAPT combines the strengths of offline policy learning in a black-box source simulator with online tube-based MPC to attenuate bounded model mismatch between the source and target dynamics. ADAPT allows online transfer of policy, trained solely in a simulation offline, to a family of unknown targets without fine-tuning. We also formally show that (i) ADAPT guarantees state and control safety through state-action tubes under the assumption of Lipschitz continuity of the divergence in dynamics and, (ii) ADAPT results in a bounded loss of reward accumulation in case of direct transfer with ADAPT as compared to a policy trained only on target. We evaluate ADAPT on 2 continuous, non-holonomic simulated dynamical systems with 4 different disturbance models, and find that ADAPT performs between 50%-300% better on mean reward accrual than direct policy transfer.</p>
</span>
<span id="bib_HarrisonGargEtAl2017" class="bibtex noshow">
	<pre>@inproceedings{HarrisonGargEtAl2017,
  author = {Harrison, J. and Garg, A. and Ivanovic, B. and Zhu, Y. and Savarese, S. and Li, F.-F. and Pavone, M.},
  title = {{ADAPT:} Zero-Shot Adaptive Policy Transfer for Stochastic Dynamical Systems},
  booktitle = {{Int. Symp. on Robotics Research}},
  year = {2017},
  address = {Puerto Varas, Chile},
  month = dec,
  url = {https://arxiv.org/pdf/1707.04674.pdf},
  owner = {pavone},
  timestamp = {2018-01-16}
}
</pre>
</span>
<!-- <span id="key_HarrisonGargEtAl2017" >
	<b>Keywords</b>:
	
</span> --></li></ol>
        
        </div>
      </div>
	  </div>
    </header>
    <!--
The website should work without any of the JS below. -F
-->

<!-- jQuery -->
<script src="https://stanfordasl.github.io/js/jquery.min.js"></script>
<!-- Bootstrap Core JavaScript -->
<script src="https://stanfordasl.github.io/js/bootstrap.min.js"></script>
<!-- Plugin JavaScript -->
<!-- <script src="js/jquery.easing.min.js"></script> -->
<!-- Contact Form JavaScript -->
<!-- <script src="js/jqBootstrapValidation.js"></script> -->
<!-- <script src="js/contact_me.js"></script> -->
<!-- Custom Theme JavaScript -->
<!-- <script src="js/freelancer.min.js"></script> -->
<!-- JabRef (Toggling info on Publications Page) -->
<script src="https://stanfordasl.github.io/js/JabRef_QuickSearch.js"></script>

    <!-- Footer -->

<!-- Scroll to Top Button (Only visible on small and extra-small screen sizes) -->
<!-- <div class="scroll-top page-scroll hidden-lg hidden-md">
    <a class="btn btn-primary" href="#page-top">
        <i class="fa fa-chevron-up"></i>
    </a>
</div> -->

<!-- Made with (L) by Federico in October 2017
CSS: Bootstrap (without the JS)
http://getbootstrap.com/
Bloated, but so convenient.
Plus, it's probably already in your browser cache (hence the CDN).
If you want the Jekyll project for your own website,
feel free to drop me a line!
-F
-->

<!-- <hr class="footer-line"/> -->
<script type="text/javascript">
function footerAlign() {
  $('footer').css('display', 'block');
  $('footer').css('height', 'auto');
  var footerHeight = $('footer').outerHeight();
  $('body').css('padding-bottom', footerHeight);
  $('footer').css('height', footerHeight);
}


$(document).ready(function(){
  footerAlign();
});

$( window ).resize(function() {
  footerAlign();
});
</script>

<footer class="footer">
<div id="social-icons">
  <a href="https://twitter.com/stanfordasl" target="_blank"><img src="https://stanfordasl.github.io/img/ASL_twitter.png" alt=""></a>
  <a href="https://www.instagram.com/stanfordasl" target="_blank"><img src="https://stanfordasl.github.io/img/ASL_instagram.png" alt=""></a>
  <a href="https://github.com/StanfordASL" target="_blank"><img src="https://stanfordasl.github.io/img/ASL_github.png" alt=""></a>
</div>
<div class="copyright-text">
  © Autonomous Systems Lab 2021. All rights reserved.
</div>
</footer>
  </body>
</html>
